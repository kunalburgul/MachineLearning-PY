{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Intro Pytorch.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pymacbit/Pytorch-PY/blob/master/Intro_Pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2B6SCTXRtkaS",
        "colab_type": "text"
      },
      "source": [
        "PyTorch is a Python-based library that provides maximum flexibility and speed.\n",
        "\n",
        "PyTorch TorchScript helps to create serializable and optimizable models. Once we train these models in Python, they can be run independently from Python as well. This helps when we’re in the model deployment stage of a data science project.\n",
        "\n",
        "So, you can train a model in PyTorch using Python and then export the model via TorchScript to a production environment where Python is not available.\n",
        "\n",
        "PyTorch also supports distributed training which enables researchers as well as practitioners to parallelize their computations. Distributed training makes it possible to use multiple GPUs to process larger batches of input data. This, in turn, reduces the computation time."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5reFqvs8uIs1",
        "colab_type": "text"
      },
      "source": [
        "## Introduction to Tensors\n",
        "\n",
        "Tensors are multidimensional arrays. And PyTorch tensors are similar to NumPy’s n-dimensional arrays. We can use these tensors on a GPU as well (this is not the case with NumPy arrays). This is a major advantage of using tensors.\n",
        "\n",
        "PyTorch supports multiple types of tensors, including:\n",
        "\n",
        "FloatTensor: 32-bit float\n",
        "DoubleTensor: 64-bit float\n",
        "HalfTensor: 16-bit float\n",
        "IntTensor: 32-bit int\n",
        "LongTensor: 64-bit int\n",
        "Now, let’s look at the basics of PyTorch along with how it compares against NumPy. We’ll start by importing both the NumPy and the Torch libraries:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4gVAzmK4uDHM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import torch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2jL1QsR_uPUl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "503bbb11-d0e6-4185-cd48-779f8fe1326b"
      },
      "source": [
        "a = np.array(1)\n",
        "b = torch.tensor(1)\n",
        "\n",
        "print(a)\n",
        "print(b)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n",
            "tensor(1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tfRDXtjRugvt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "87df948a-ba84-486d-f146-4d3dc89630a6"
      },
      "source": [
        "type(a), type(b)\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(numpy.ndarray, torch.Tensor)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yP-sqZgPu3rh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "d2614bf0-ef6f-4cf7-8e6c-69ca3175d239"
      },
      "source": [
        "# mathematical operations \n",
        "\n",
        "a = np.array(1)\n",
        "b = np.array(2)\n",
        "\n",
        "print (a,b)\n",
        "\n",
        "#addition\n",
        "print(a+b)\n",
        "\n",
        "# subtraction\n",
        "print(b-a)\n",
        "\n",
        "# multiplication\n",
        "print(a*b)\n",
        "\n",
        "# division\n",
        "print(a/b)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 2\n",
            "3\n",
            "1\n",
            "2\n",
            "0.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OLPhOHDyvPp8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "fa05f782-50bf-49dc-bf59-172c4b1a915d"
      },
      "source": [
        "a = torch.tensor(1)\n",
        "b = torch.tensor(2)\n",
        "\n",
        "print (a,b)\n",
        "\n",
        "#addition\n",
        "print(a+b)\n",
        "\n",
        "# subtraction\n",
        "print(b-a)\n",
        "\n",
        "# multiplication\n",
        "print(a*b)\n",
        "\n",
        "# division\n",
        "print(a/b)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(1) tensor(2)\n",
            "tensor(3)\n",
            "tensor(1)\n",
            "tensor(2)\n",
            "tensor(0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SVFYDu-Xvm4N",
        "colab_type": "text"
      },
      "source": [
        "### Matrix Initialization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_QXxpqOmvbA1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "91692a3d-13b5-47ea-dea3-006a1bb6e2d5"
      },
      "source": [
        "# Let’s say we want a matrix of shape 3*3 having all zeros. Take a moment to think – how can we do that using NumPy?\n",
        "\n",
        "a = np.zeros((3,3))\n",
        "print(a)\n",
        "print(a.shape)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "(3, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TZ1PX3GTv48K",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "d6498142-2d55-432c-c329-199149b2793d"
      },
      "source": [
        "a = torch.zeros((3,3))\n",
        "print(a)\n",
        "print(a.shape)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0., 0., 0.],\n",
            "        [0., 0., 0.],\n",
            "        [0., 0., 0.]])\n",
            "torch.Size([3, 3])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nEbs3Ssfv-lK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "f70297a5-3bd5-481f-8861-1917d0232a4a"
      },
      "source": [
        "# let’s see how we can initialize a matrix with random numbers:\n",
        "\n",
        "np.random.seed(42)\n",
        "\n",
        "# We have specified the random seed at the beginning here so that every time we run the above code, the same random number will generate.\n",
        "\n",
        "a = np.random.randn(3,3)\n",
        "\n",
        "# The random.randn() function returns random numbers that follow a standard normal distribution.\n",
        "\n",
        "a"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.49671415, -0.1382643 ,  0.64768854],\n",
              "       [ 1.52302986, -0.23415337, -0.23413696],\n",
              "       [ 1.57921282,  0.76743473, -0.46947439]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k5ZoLBTGwZiM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "3b64a1c0-854b-4137-d40f-7a54593a61a7"
      },
      "source": [
        "# setting the random seed for pytorch\n",
        "torch.manual_seed(42)\n",
        "# matrix of random numbers\n",
        "a = torch.randn(3,3)\n",
        "a"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.3367,  0.1288,  0.2345],\n",
              "        [ 0.2303, -1.1229, -0.1863],\n",
              "        [ 2.2082, -0.6380,  0.4617]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "56tY8G22w8hm",
        "colab_type": "text"
      },
      "source": [
        "### Matrix operation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qO4_LLjHws1M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "1eb32973-855e-4d1b-9c6d-bc5a2d675a7c"
      },
      "source": [
        "# setting the random seed for numpy and initializing two matrices\n",
        "np.random.seed(42)\n",
        "a = np.random.randn(3,3)\n",
        "b = np.random.randn(3,3)\n",
        "\n",
        "# matrix addition\n",
        "print(np.add(a,b), '\\n')\n",
        "\n",
        "# matrix subtraction\n",
        "print(np.subtract(a,b), '\\n')\n",
        "\n",
        "# matrix multiplication\n",
        "print(np.dot(a,b), '\\n')\n",
        "\n",
        "# matrix multiplication\n",
        "print(np.divide(a,b))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 1.0392742  -0.60168199  0.18195878]\n",
            " [ 1.76499213 -2.14743362 -1.95905479]\n",
            " [ 1.01692529 -0.24539639 -0.15522705]] \n",
            "\n",
            "[[-0.04584589  0.32515339  1.11341829]\n",
            " [ 1.28106758  1.67912687  1.49078088]\n",
            " [ 2.14150034  1.78026585 -0.78372172]] \n",
            "\n",
            "[[-0.12814468 -0.62164688  0.21069439]\n",
            " [ 0.90133115 -0.02065676 -0.3790019 ]\n",
            " [ 1.30648762 -1.7246546  -2.20677932]] \n",
            "\n",
            "[[ 0.9155008   0.29835784 -1.39069607]\n",
            " [ 6.29449313  0.12238321  0.13573803]\n",
            " [-2.80855031 -0.75771243 -1.49396459]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZJNEJyuhxKEe",
        "colab_type": "text"
      },
      "source": [
        "Matrix transpose is one technique which is also very useful while creating a neural network from scratch. So let’s see how we take the transpose of a matrix in NumPy:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pg7qRA28xDnS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "c2f7b2e9-731d-4329-b6d5-62825429c06f"
      },
      "source": [
        "\n",
        "# original matrix\n",
        "print(a, '\\n')\n",
        "\n",
        "# matrix transpose\n",
        "print(np.transpose(a))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 0.49671415 -0.1382643   0.64768854]\n",
            " [ 1.52302986 -0.23415337 -0.23413696]\n",
            " [ 1.57921282  0.76743473 -0.46947439]] \n",
            "\n",
            "[[ 0.49671415  1.52302986  1.57921282]\n",
            " [-0.1382643  -0.23415337  0.76743473]\n",
            " [ 0.64768854 -0.23413696 -0.46947439]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "28xmmJnCxMcM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "7c492cd5-cee9-42a1-aa06-5de07a5eb562"
      },
      "source": [
        "torch.manual_seed(42)\n",
        "\n",
        "a = torch.randn(3,3)\n",
        "b = torch.randn(3,3)\n",
        "\n",
        "# matrix addition\n",
        "print(torch.add(a,b), '\\n')\n",
        "\n",
        "# matrix subtraction\n",
        "print(torch.sub(a,b), '\\n')\n",
        "\n",
        "# matrix multiplication\n",
        "print(torch.mm(a,b), '\\n')\n",
        "\n",
        "# matrix division\n",
        "print(torch.div(a,b))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 0.6040,  0.6637,  1.0438],\n",
            "        [ 1.3406, -2.8127, -1.1753],\n",
            "        [ 3.1662,  0.6841,  1.2788]]) \n",
            "\n",
            "tensor([[ 0.0693, -0.4061, -0.5749],\n",
            "        [-0.8800,  0.5669,  0.8026],\n",
            "        [ 1.2502, -1.9601, -0.3555]]) \n",
            "\n",
            "tensor([[ 0.4576,  0.2724,  0.3367],\n",
            "        [-1.3636,  1.7743,  1.1446],\n",
            "        [ 0.3243,  2.8696,  2.7954]]) \n",
            "\n",
            "tensor([[ 1.2594,  0.2408,  0.2897],\n",
            "        [ 0.2075,  0.6645,  0.1884],\n",
            "        [ 2.3051, -0.4826,  0.5649]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5t9Ys8rfxclo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "9b8ca20f-7d4e-4e7b-c77d-b688561ff152"
      },
      "source": [
        "# original matrix\n",
        "print(a, '\\n')\n",
        "\n",
        "# matrix transpose\n",
        "torch.t(a)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 0.3367,  0.1288,  0.2345],\n",
            "        [ 0.2303, -1.1229, -0.1863],\n",
            "        [ 2.2082, -0.6380,  0.4617]]) \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.3367,  0.2303,  2.2082],\n",
              "        [ 0.1288, -1.1229, -0.6380],\n",
              "        [ 0.2345, -0.1863,  0.4617]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FuBSbRyUxqbN",
        "colab_type": "text"
      },
      "source": [
        "### Concat & Reshape tensors "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qjWcOZvlxgVe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "b8b95715-1700-43f8-94c0-8bff4f8df2e8"
      },
      "source": [
        "# initializing two tensors\n",
        "a = torch.tensor([[1,2],[3,4]])\n",
        "b = torch.tensor([[5,6],[7,8]])\n",
        "print(a, '\\n')\n",
        "print(b)\n",
        "\n",
        "# concatenating vertically\n",
        "torch.cat((a,b))\n",
        "\n",
        "# concatenating horizontally\n",
        "torch.cat((a,b),dim=1)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1, 2],\n",
            "        [3, 4]]) \n",
            "\n",
            "tensor([[5, 6],\n",
            "        [7, 8]])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 2, 5, 6],\n",
              "        [3, 4, 7, 8]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F8VtIhOnxy6G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "0b3a22df-32d4-46e9-85f9-864af46b35c6"
      },
      "source": [
        "# setting the random seed for pytorch\n",
        "torch.manual_seed(42)\n",
        "# initializing tensor\n",
        "a = torch.randn(2,4)\n",
        "print(a)\n",
        "a.shape"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 0.3367,  0.1288,  0.2345,  0.2303],\n",
            "        [-1.1229, -0.1863,  2.2082, -0.6380]])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 4])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dNcnOi0XyDNZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "1a04c4a8-4513-4d63-ab03-72bf93a98621"
      },
      "source": [
        "# reshaping tensor\n",
        "b = a.reshape(1,8)\n",
        "print(b)\n",
        "b.shape"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 0.3367,  0.1288,  0.2345,  0.2303, -1.1229, -0.1863,  2.2082, -0.6380]])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 8])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YgoxRki5yFp4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# initializing a numpy array\n",
        "a = np.array([[1,2],[3,4]])\n",
        "print(a, '\\n')\n",
        "\n",
        "# converting the numpy array to tensor\n",
        "tensor = torch.from_numpy(a)\n",
        "print(tensor)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lUIVjFPayvA3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "e998349f-b3d8-446b-f111-4f694811285d"
      },
      "source": [
        "# Convert numpy arrays to tensor \n",
        "\n",
        "a = np.array([[1,2],[3,4]])\n",
        "print(a, '\\n')\n",
        "\n",
        "# converting the numpy array to tensor\n",
        "tensor = torch.from_numpy(a)\n",
        "print(tensor)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1 2]\n",
            " [3 4]] \n",
            "\n",
            "tensor([[1, 2],\n",
            "        [3, 4]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OXJu5suSzUxw",
        "colab_type": "text"
      },
      "source": [
        "## Common Pytorch modules "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CYLOCkpzFPKm",
        "colab_type": "text"
      },
      "source": [
        "### Autograd Module\n",
        "\n",
        "\n",
        "PyTorch uses a technique called automatic differentiation. It records all the operations that we are performing and replays it backward to compute gradients. This technique helps us to save time on each epoch as we are calculating the gradients on the forward pass itself."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0_PPw3c1zBkm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "c75cfb5e-f43f-46ac-96c5-a2d01fe58260"
      },
      "source": [
        "# initializing a tensor\n",
        "a = torch.ones((2,2), requires_grad=True)\n",
        "a"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 1.],\n",
              "        [1., 1.]], requires_grad=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dECAhxQ3Ffbf",
        "colab_type": "text"
      },
      "source": [
        "Here, we have initialized a tensor. Specifying requires_grad as True will make sure that the gradients are stored for this particular tensor whenever we perform some operation on it. Let’s now perform some operations on the defined tensor:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d5VtRy4dFVmT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "32ebb543-2459-4f9e-c9ff-efda6a30ab26"
      },
      "source": [
        "# performing operations on the tensor\n",
        "b = a + 5\n",
        "c = b.mean()\n",
        "print(b,c)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[6., 6.],\n",
            "        [6., 6.]], grad_fn=<AddBackward0>) tensor(6., grad_fn=<MeanBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eJPG06ucFn98",
        "colab_type": "text"
      },
      "source": [
        "First of all, we added 5 to all the elements of this tensor and then taken the mean of that tensor. We will first manually calculate the gradients and then verify that using PyTorch. We performed the following operations on a:\n",
        "\n",
        "b = a + 5\n",
        "\n",
        "c = mean(b) = Σ(a+5) / 4\n",
        "\n",
        "Now, the derivative of c w.r.t. a will be ¼ and hence the gradient matrix will be 0.25. Let’s verify this using PyTorch:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UZ-f16FVFiV5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "c98c1999-8428-4915-b413-f766efb21fd4"
      },
      "source": [
        "# back propagating\n",
        "c.backward()\n",
        "\n",
        "# computing gradients\n",
        "print(a.grad)\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.2500, 0.2500],\n",
            "        [0.2500, 0.2500]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rjPliQGaFyPB",
        "colab_type": "text"
      },
      "source": [
        "### Optim Module\n",
        "\n",
        "The Optim module in PyTorch has pre-written codes for most of the optimizers that are used while building a neural network. We just have to import them and then they can be used to build models.\n",
        "\n",
        "Let’s see how we can use an optimizer in PyTorch:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oUEPMiuHFqus",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# importing the optim module\n",
        "from torch import optim\n",
        "\n",
        "# adam\n",
        "## adam = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# sgd\n",
        "## SGD = optim.SGD(model.parameters(), lr=learning_rate)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cQbnJ2dpF-yW",
        "colab_type": "text"
      },
      "source": [
        "Above are the examples to get the ADAM and SGD optimizers. Most of the commonly used optimizers are supported in PyTorch and hence we do not have to write them from scratch. Some of them are:\n",
        "\n",
        "SGD\n",
        "Adam\n",
        "Adadelta\n",
        "Adagrad\n",
        "AdamW\n",
        "SparseAdam\n",
        "Adamax\n",
        "ASGD (Averaged Stochastic Gradient Descent)\n",
        "RMSprop\n",
        "Rprop (resilient backpropagation)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wcOr24prF6VC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}