{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression - California Housing Data\n",
    "\n",
    "California Housing Data\n",
    "\n",
    "This data set contains information about all the block groups in California from the 1990 Census. In this sample a block group on average includes 1425.5 individuals living in a geographically compact area. \n",
    "\n",
    "The task is to aproximate the median house value of each block from the values of the rest of the variables. \n",
    "\n",
    " It has been obtained from the LIACC repository. The original page where the data set can be found is: http://www.liaad.up.pt/~ltorgo/Regression/DataSets.html.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Features:\n",
    " \n",
    "* housingMedianAge: continuous. \n",
    "* totalRooms: continuous. \n",
    "* totalBedrooms: continuous. \n",
    "* population: continuous. \n",
    "* households: continuous. \n",
    "* medianIncome: continuous. \n",
    "* medianHouseValue: continuous. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Import the cal_housing.csv file with pandas. Separate it into a training (70%) and testing set(30%).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing = pd.read_csv('cal_housing_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>housingMedianAge</th>\n",
       "      <th>totalRooms</th>\n",
       "      <th>totalBedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>medianIncome</th>\n",
       "      <th>medianHouseValue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41.0</td>\n",
       "      <td>880.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>322.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>8.3252</td>\n",
       "      <td>452600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21.0</td>\n",
       "      <td>7099.0</td>\n",
       "      <td>1106.0</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>1138.0</td>\n",
       "      <td>8.3014</td>\n",
       "      <td>358500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>52.0</td>\n",
       "      <td>1467.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>496.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>7.2574</td>\n",
       "      <td>352100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>52.0</td>\n",
       "      <td>1274.0</td>\n",
       "      <td>235.0</td>\n",
       "      <td>558.0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>5.6431</td>\n",
       "      <td>341300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>52.0</td>\n",
       "      <td>1627.0</td>\n",
       "      <td>280.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>259.0</td>\n",
       "      <td>3.8462</td>\n",
       "      <td>342200.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   housingMedianAge  totalRooms  totalBedrooms  population  households  \\\n",
       "0              41.0       880.0          129.0       322.0       126.0   \n",
       "1              21.0      7099.0         1106.0      2401.0      1138.0   \n",
       "2              52.0      1467.0          190.0       496.0       177.0   \n",
       "3              52.0      1274.0          235.0       558.0       219.0   \n",
       "4              52.0      1627.0          280.0       565.0       259.0   \n",
       "\n",
       "   medianIncome  medianHouseValue  \n",
       "0        8.3252          452600.0  \n",
       "1        8.3014          358500.0  \n",
       "2        7.2574          352100.0  \n",
       "3        5.6431          341300.0  \n",
       "4        3.8462          342200.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>housingMedianAge</th>\n",
       "      <td>20640.0</td>\n",
       "      <td>28.639486</td>\n",
       "      <td>12.585558</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>18.0000</td>\n",
       "      <td>29.0000</td>\n",
       "      <td>37.00000</td>\n",
       "      <td>52.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>totalRooms</th>\n",
       "      <td>20640.0</td>\n",
       "      <td>2635.763081</td>\n",
       "      <td>2181.615252</td>\n",
       "      <td>2.0000</td>\n",
       "      <td>1447.7500</td>\n",
       "      <td>2127.0000</td>\n",
       "      <td>3148.00000</td>\n",
       "      <td>39320.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>totalBedrooms</th>\n",
       "      <td>20640.0</td>\n",
       "      <td>537.898014</td>\n",
       "      <td>421.247906</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>295.0000</td>\n",
       "      <td>435.0000</td>\n",
       "      <td>647.00000</td>\n",
       "      <td>6445.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>population</th>\n",
       "      <td>20640.0</td>\n",
       "      <td>1425.476744</td>\n",
       "      <td>1132.462122</td>\n",
       "      <td>3.0000</td>\n",
       "      <td>787.0000</td>\n",
       "      <td>1166.0000</td>\n",
       "      <td>1725.00000</td>\n",
       "      <td>35682.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>households</th>\n",
       "      <td>20640.0</td>\n",
       "      <td>499.539680</td>\n",
       "      <td>382.329753</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>280.0000</td>\n",
       "      <td>409.0000</td>\n",
       "      <td>605.00000</td>\n",
       "      <td>6082.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>medianIncome</th>\n",
       "      <td>20640.0</td>\n",
       "      <td>3.870671</td>\n",
       "      <td>1.899822</td>\n",
       "      <td>0.4999</td>\n",
       "      <td>2.5634</td>\n",
       "      <td>3.5348</td>\n",
       "      <td>4.74325</td>\n",
       "      <td>15.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>medianHouseValue</th>\n",
       "      <td>20640.0</td>\n",
       "      <td>206855.816909</td>\n",
       "      <td>115395.615874</td>\n",
       "      <td>14999.0000</td>\n",
       "      <td>119600.0000</td>\n",
       "      <td>179700.0000</td>\n",
       "      <td>264725.00000</td>\n",
       "      <td>500001.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    count           mean            std         min  \\\n",
       "housingMedianAge  20640.0      28.639486      12.585558      1.0000   \n",
       "totalRooms        20640.0    2635.763081    2181.615252      2.0000   \n",
       "totalBedrooms     20640.0     537.898014     421.247906      1.0000   \n",
       "population        20640.0    1425.476744    1132.462122      3.0000   \n",
       "households        20640.0     499.539680     382.329753      1.0000   \n",
       "medianIncome      20640.0       3.870671       1.899822      0.4999   \n",
       "medianHouseValue  20640.0  206855.816909  115395.615874  14999.0000   \n",
       "\n",
       "                          25%          50%           75%          max  \n",
       "housingMedianAge      18.0000      29.0000      37.00000      52.0000  \n",
       "totalRooms          1447.7500    2127.0000    3148.00000   39320.0000  \n",
       "totalBedrooms        295.0000     435.0000     647.00000    6445.0000  \n",
       "population           787.0000    1166.0000    1725.00000   35682.0000  \n",
       "households           280.0000     409.0000     605.00000    6082.0000  \n",
       "medianIncome           2.5634       3.5348       4.74325      15.0001  \n",
       "medianHouseValue  119600.0000  179700.0000  264725.00000  500001.0000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing.describe().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_data = housing.drop(['medianHouseValue'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val = housing['medianHouseValue']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(x_data,y_val,test_size=0.3,random_state=101)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scale the Feature Data\n",
    "\n",
    "** Use sklearn preprocessing to create a MinMaxScaler for the feature data. Fit this scaler only to the training data. Then use it to transform X_test and X_train. Then use the scaled X_test and X_train along with pd.Dataframe to re-create two dataframes of scaled data.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MinMaxScaler(copy=True, feature_range=(0, 1))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.DataFrame(data=scaler.transform(X_train),columns = X_train.columns,index=X_train.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = pd.DataFrame(data=scaler.transform(X_test),columns = X_test.columns,index=X_test.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Feature Columns\n",
    "\n",
    "** Create the necessary tf.feature_column objects for the estimator. They should all be trated as continuous numeric_columns. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['housingMedianAge', 'totalRooms', 'totalBedrooms', 'population',\n",
       "       'households', 'medianIncome', 'medianHouseValue'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "age = tf.feature_column.numeric_column('housingMedianAge')\n",
    "rooms = tf.feature_column.numeric_column('totalRooms')\n",
    "bedrooms = tf.feature_column.numeric_column('totalBedrooms')\n",
    "pop = tf.feature_column.numeric_column('population')\n",
    "households = tf.feature_column.numeric_column('households')\n",
    "income = tf.feature_column.numeric_column('medianIncome')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_cols = [ age,rooms,bedrooms,pop,households,income]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Create the input function for the estimator object. (play around with batch_size and num_epochs)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_func = tf.estimator.inputs.pandas_input_fn(x=X_train,y=y_train ,batch_size=10,num_epochs=1000,\n",
    "                                            shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Create the estimator model. Use a DNNRegressor. Play around with the hidden units! **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /var/folders/0y/41vh8h4d1wv2yccr48slhmgc0000gn/T/tmpzyv8rm11\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/var/folders/0y/41vh8h4d1wv2yccr48slhmgc0000gn/T/tmpzyv8rm11', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x1a3d718b70>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "model = tf.estimator.DNNRegressor(hidden_units=[6,6,6],feature_columns=feat_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ** Train the model for ~1,000 steps. (Later come back to this and train it for more and check for improvement) **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/pymacbit/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
      "WARNING:tensorflow:From /Users/pymacbit/anaconda3/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/inputs/queues/feeding_queue_runner.py:62: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:From /Users/pymacbit/anaconda3/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/inputs/queues/feeding_functions.py:500: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:From /Users/pymacbit/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From /Users/pymacbit/anaconda3/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/canned/head.py:437: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "WARNING:tensorflow:From /Users/pymacbit/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/training/adagrad.py:76: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "WARNING:tensorflow:From /Users/pymacbit/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/ops/array_ops.py:1475: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "WARNING:tensorflow:From /Users/pymacbit/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/training/monitored_session.py:882: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into /var/folders/0y/41vh8h4d1wv2yccr48slhmgc0000gn/T/tmpzyv8rm11/model.ckpt.\n",
      "INFO:tensorflow:loss = 445014150000.0, step = 1\n",
      "INFO:tensorflow:global_step/sec: 132.289\n",
      "INFO:tensorflow:loss = 379150340000.0, step = 101 (0.756 sec)\n",
      "INFO:tensorflow:global_step/sec: 317.517\n",
      "INFO:tensorflow:loss = 513966150000.0, step = 201 (0.315 sec)\n",
      "INFO:tensorflow:global_step/sec: 314.941\n",
      "INFO:tensorflow:loss = 591803200000.0, step = 301 (0.317 sec)\n",
      "INFO:tensorflow:global_step/sec: 353.282\n",
      "INFO:tensorflow:loss = 248412400000.0, step = 401 (0.283 sec)\n",
      "INFO:tensorflow:global_step/sec: 335.373\n",
      "INFO:tensorflow:loss = 498971050000.0, step = 501 (0.298 sec)\n",
      "INFO:tensorflow:global_step/sec: 329.376\n",
      "INFO:tensorflow:loss = 263930890000.0, step = 601 (0.304 sec)\n",
      "INFO:tensorflow:global_step/sec: 312.962\n",
      "INFO:tensorflow:loss = 322745530000.0, step = 701 (0.319 sec)\n",
      "INFO:tensorflow:global_step/sec: 311.124\n",
      "INFO:tensorflow:loss = 245416050000.0, step = 801 (0.321 sec)\n",
      "INFO:tensorflow:global_step/sec: 318.196\n",
      "INFO:tensorflow:loss = 240187670000.0, step = 901 (0.314 sec)\n",
      "INFO:tensorflow:global_step/sec: 333.315\n",
      "INFO:tensorflow:loss = 133620790000.0, step = 1001 (0.300 sec)\n",
      "INFO:tensorflow:global_step/sec: 339.031\n",
      "INFO:tensorflow:loss = 212636630000.0, step = 1101 (0.295 sec)\n",
      "INFO:tensorflow:global_step/sec: 338.776\n",
      "INFO:tensorflow:loss = 232111240000.0, step = 1201 (0.295 sec)\n",
      "INFO:tensorflow:global_step/sec: 318.072\n",
      "INFO:tensorflow:loss = 51438000000.0, step = 1301 (0.314 sec)\n",
      "INFO:tensorflow:global_step/sec: 336.615\n",
      "INFO:tensorflow:loss = 66666037000.0, step = 1401 (0.297 sec)\n",
      "INFO:tensorflow:global_step/sec: 295.709\n",
      "INFO:tensorflow:loss = 91546700000.0, step = 1501 (0.338 sec)\n",
      "INFO:tensorflow:global_step/sec: 301.77\n",
      "INFO:tensorflow:loss = 191123590000.0, step = 1601 (0.338 sec)\n",
      "INFO:tensorflow:global_step/sec: 279.547\n",
      "INFO:tensorflow:loss = 101920650000.0, step = 1701 (0.357 sec)\n",
      "INFO:tensorflow:global_step/sec: 302.283\n",
      "INFO:tensorflow:loss = 84858360000.0, step = 1801 (0.327 sec)\n",
      "INFO:tensorflow:global_step/sec: 318.934\n",
      "INFO:tensorflow:loss = 65304400000.0, step = 1901 (0.313 sec)\n",
      "INFO:tensorflow:global_step/sec: 300.337\n",
      "INFO:tensorflow:loss = 79870230000.0, step = 2001 (0.332 sec)\n",
      "INFO:tensorflow:global_step/sec: 293.963\n",
      "INFO:tensorflow:loss = 71206160000.0, step = 2101 (0.340 sec)\n",
      "INFO:tensorflow:global_step/sec: 288.704\n",
      "INFO:tensorflow:loss = 147864760000.0, step = 2201 (0.347 sec)\n",
      "INFO:tensorflow:global_step/sec: 296.434\n",
      "INFO:tensorflow:loss = 88222780000.0, step = 2301 (0.338 sec)\n",
      "INFO:tensorflow:global_step/sec: 269.042\n",
      "INFO:tensorflow:loss = 105743870000.0, step = 2401 (0.372 sec)\n",
      "INFO:tensorflow:global_step/sec: 276.745\n",
      "INFO:tensorflow:loss = 147939950000.0, step = 2501 (0.362 sec)\n",
      "INFO:tensorflow:global_step/sec: 301.817\n",
      "INFO:tensorflow:loss = 147198310000.0, step = 2601 (0.330 sec)\n",
      "INFO:tensorflow:global_step/sec: 304.383\n",
      "INFO:tensorflow:loss = 42960077000.0, step = 2701 (0.329 sec)\n",
      "INFO:tensorflow:global_step/sec: 298.145\n",
      "INFO:tensorflow:loss = 87507870000.0, step = 2801 (0.335 sec)\n",
      "INFO:tensorflow:global_step/sec: 282.914\n",
      "INFO:tensorflow:loss = 121446646000.0, step = 2901 (0.354 sec)\n",
      "INFO:tensorflow:global_step/sec: 295.852\n",
      "INFO:tensorflow:loss = 51889470000.0, step = 3001 (0.338 sec)\n",
      "INFO:tensorflow:global_step/sec: 318.076\n",
      "INFO:tensorflow:loss = 124526050000.0, step = 3101 (0.314 sec)\n",
      "INFO:tensorflow:global_step/sec: 303.239\n",
      "INFO:tensorflow:loss = 124186180000.0, step = 3201 (0.330 sec)\n",
      "INFO:tensorflow:global_step/sec: 297.346\n",
      "INFO:tensorflow:loss = 183160540000.0, step = 3301 (0.336 sec)\n",
      "INFO:tensorflow:global_step/sec: 314.938\n",
      "INFO:tensorflow:loss = 120498760000.0, step = 3401 (0.317 sec)\n",
      "INFO:tensorflow:global_step/sec: 292.269\n",
      "INFO:tensorflow:loss = 144672690000.0, step = 3501 (0.342 sec)\n",
      "INFO:tensorflow:global_step/sec: 307.38\n",
      "INFO:tensorflow:loss = 182553870000.0, step = 3601 (0.326 sec)\n",
      "INFO:tensorflow:global_step/sec: 293.87\n",
      "INFO:tensorflow:loss = 99013435000.0, step = 3701 (0.340 sec)\n",
      "INFO:tensorflow:global_step/sec: 277.816\n",
      "INFO:tensorflow:loss = 116547220000.0, step = 3801 (0.360 sec)\n",
      "INFO:tensorflow:global_step/sec: 348.143\n",
      "INFO:tensorflow:loss = 83758055000.0, step = 3901 (0.287 sec)\n",
      "INFO:tensorflow:global_step/sec: 337.2\n",
      "INFO:tensorflow:loss = 131820850000.0, step = 4001 (0.296 sec)\n",
      "INFO:tensorflow:global_step/sec: 277.121\n",
      "INFO:tensorflow:loss = 110378205000.0, step = 4101 (0.361 sec)\n",
      "INFO:tensorflow:global_step/sec: 251.833\n",
      "INFO:tensorflow:loss = 171191370000.0, step = 4201 (0.397 sec)\n",
      "INFO:tensorflow:global_step/sec: 294.222\n",
      "INFO:tensorflow:loss = 81418610000.0, step = 4301 (0.340 sec)\n",
      "INFO:tensorflow:global_step/sec: 298.334\n",
      "INFO:tensorflow:loss = 49154793000.0, step = 4401 (0.335 sec)\n",
      "INFO:tensorflow:global_step/sec: 212.377\n",
      "INFO:tensorflow:loss = 41782362000.0, step = 4501 (0.471 sec)\n",
      "INFO:tensorflow:global_step/sec: 266.556\n",
      "INFO:tensorflow:loss = 113537114000.0, step = 4601 (0.375 sec)\n",
      "INFO:tensorflow:global_step/sec: 233.896\n",
      "INFO:tensorflow:loss = 70293230000.0, step = 4701 (0.428 sec)\n",
      "INFO:tensorflow:global_step/sec: 302.443\n",
      "INFO:tensorflow:loss = 209020650000.0, step = 4801 (0.331 sec)\n",
      "INFO:tensorflow:global_step/sec: 296.042\n",
      "INFO:tensorflow:loss = 72582440000.0, step = 4901 (0.338 sec)\n",
      "INFO:tensorflow:global_step/sec: 316.277\n",
      "INFO:tensorflow:loss = 113331060000.0, step = 5001 (0.316 sec)\n",
      "INFO:tensorflow:global_step/sec: 312.486\n",
      "INFO:tensorflow:loss = 99673910000.0, step = 5101 (0.320 sec)\n",
      "INFO:tensorflow:global_step/sec: 298.53\n",
      "INFO:tensorflow:loss = 46950306000.0, step = 5201 (0.335 sec)\n",
      "INFO:tensorflow:global_step/sec: 301.771\n",
      "INFO:tensorflow:loss = 186530430000.0, step = 5301 (0.331 sec)\n",
      "INFO:tensorflow:global_step/sec: 291.869\n",
      "INFO:tensorflow:loss = 75754630000.0, step = 5401 (0.343 sec)\n",
      "INFO:tensorflow:global_step/sec: 300.567\n",
      "INFO:tensorflow:loss = 145256870000.0, step = 5501 (0.332 sec)\n",
      "INFO:tensorflow:global_step/sec: 293.138\n",
      "INFO:tensorflow:loss = 108790500000.0, step = 5601 (0.341 sec)\n",
      "INFO:tensorflow:global_step/sec: 294.364\n",
      "INFO:tensorflow:loss = 35824493000.0, step = 5701 (0.339 sec)\n",
      "INFO:tensorflow:global_step/sec: 293.004\n",
      "INFO:tensorflow:loss = 47571190000.0, step = 5801 (0.342 sec)\n",
      "INFO:tensorflow:global_step/sec: 272.544\n",
      "INFO:tensorflow:loss = 21041970000.0, step = 5901 (0.368 sec)\n",
      "INFO:tensorflow:global_step/sec: 270.4\n",
      "INFO:tensorflow:loss = 48115190000.0, step = 6001 (0.371 sec)\n",
      "INFO:tensorflow:global_step/sec: 277.406\n",
      "INFO:tensorflow:loss = 153158480000.0, step = 6101 (0.364 sec)\n",
      "INFO:tensorflow:global_step/sec: 295.065\n",
      "INFO:tensorflow:loss = 119391950000.0, step = 6201 (0.334 sec)\n",
      "INFO:tensorflow:global_step/sec: 312.931\n",
      "INFO:tensorflow:loss = 163757950000.0, step = 6301 (0.320 sec)\n",
      "INFO:tensorflow:global_step/sec: 305.653\n",
      "INFO:tensorflow:loss = 75002460000.0, step = 6401 (0.327 sec)\n",
      "INFO:tensorflow:global_step/sec: 261.367\n",
      "INFO:tensorflow:loss = 89987920000.0, step = 6501 (0.382 sec)\n",
      "INFO:tensorflow:global_step/sec: 302.498\n",
      "INFO:tensorflow:loss = 158410390000.0, step = 6601 (0.331 sec)\n",
      "INFO:tensorflow:global_step/sec: 289.822\n",
      "INFO:tensorflow:loss = 81020600000.0, step = 6701 (0.345 sec)\n",
      "INFO:tensorflow:global_step/sec: 289.374\n",
      "INFO:tensorflow:loss = 122552150000.0, step = 6801 (0.346 sec)\n",
      "INFO:tensorflow:global_step/sec: 280.08\n",
      "INFO:tensorflow:loss = 104136380000.0, step = 6901 (0.356 sec)\n",
      "INFO:tensorflow:global_step/sec: 300.54\n",
      "INFO:tensorflow:loss = 101113790000.0, step = 7001 (0.333 sec)\n",
      "INFO:tensorflow:global_step/sec: 297.575\n",
      "INFO:tensorflow:loss = 125466870000.0, step = 7101 (0.336 sec)\n",
      "INFO:tensorflow:global_step/sec: 307.044\n",
      "INFO:tensorflow:loss = 45953090000.0, step = 7201 (0.325 sec)\n",
      "INFO:tensorflow:global_step/sec: 314.089\n",
      "INFO:tensorflow:loss = 94925010000.0, step = 7301 (0.319 sec)\n",
      "INFO:tensorflow:global_step/sec: 284.427\n",
      "INFO:tensorflow:loss = 28088867000.0, step = 7401 (0.351 sec)\n",
      "INFO:tensorflow:global_step/sec: 329.451\n",
      "INFO:tensorflow:loss = 111002990000.0, step = 7501 (0.303 sec)\n",
      "INFO:tensorflow:global_step/sec: 278.119\n",
      "INFO:tensorflow:loss = 121770390000.0, step = 7601 (0.360 sec)\n",
      "INFO:tensorflow:global_step/sec: 282.392\n",
      "INFO:tensorflow:loss = 90595100000.0, step = 7701 (0.354 sec)\n",
      "INFO:tensorflow:global_step/sec: 291.678\n",
      "INFO:tensorflow:loss = 83860360000.0, step = 7801 (0.343 sec)\n",
      "INFO:tensorflow:global_step/sec: 309.266\n",
      "INFO:tensorflow:loss = 82948465000.0, step = 7901 (0.324 sec)\n",
      "INFO:tensorflow:global_step/sec: 295.805\n",
      "INFO:tensorflow:loss = 78384914000.0, step = 8001 (0.338 sec)\n",
      "INFO:tensorflow:global_step/sec: 296.722\n",
      "INFO:tensorflow:loss = 58138694000.0, step = 8101 (0.337 sec)\n",
      "INFO:tensorflow:global_step/sec: 311.597\n",
      "INFO:tensorflow:loss = 102629650000.0, step = 8201 (0.321 sec)\n",
      "INFO:tensorflow:global_step/sec: 290.261\n",
      "INFO:tensorflow:loss = 195056780000.0, step = 8301 (0.344 sec)\n",
      "INFO:tensorflow:global_step/sec: 305.491\n",
      "INFO:tensorflow:loss = 124860236000.0, step = 8401 (0.327 sec)\n",
      "INFO:tensorflow:global_step/sec: 294.443\n",
      "INFO:tensorflow:loss = 141053400000.0, step = 8501 (0.340 sec)\n",
      "INFO:tensorflow:global_step/sec: 311.415\n",
      "INFO:tensorflow:loss = 89650830000.0, step = 8601 (0.321 sec)\n",
      "INFO:tensorflow:global_step/sec: 310.802\n",
      "INFO:tensorflow:loss = 166432100000.0, step = 8701 (0.322 sec)\n",
      "INFO:tensorflow:global_step/sec: 277.664\n",
      "INFO:tensorflow:loss = 158174230000.0, step = 8801 (0.360 sec)\n",
      "INFO:tensorflow:global_step/sec: 326.365\n",
      "INFO:tensorflow:loss = 52263215000.0, step = 8901 (0.306 sec)\n",
      "INFO:tensorflow:global_step/sec: 315.755\n",
      "INFO:tensorflow:loss = 148697740000.0, step = 9001 (0.317 sec)\n",
      "INFO:tensorflow:global_step/sec: 292.444\n",
      "INFO:tensorflow:loss = 68336607000.0, step = 9101 (0.341 sec)\n",
      "INFO:tensorflow:global_step/sec: 309.078\n",
      "INFO:tensorflow:loss = 80563310000.0, step = 9201 (0.324 sec)\n",
      "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 9202 vs previous value: 9202. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
      "INFO:tensorflow:global_step/sec: 308.215\n",
      "INFO:tensorflow:loss = 77380250000.0, step = 9301 (0.324 sec)\n",
      "INFO:tensorflow:global_step/sec: 312.956\n",
      "INFO:tensorflow:loss = 77453770000.0, step = 9401 (0.320 sec)\n",
      "INFO:tensorflow:global_step/sec: 320.58\n",
      "INFO:tensorflow:loss = 142253410000.0, step = 9501 (0.312 sec)\n",
      "INFO:tensorflow:global_step/sec: 298.428\n",
      "INFO:tensorflow:loss = 65223950000.0, step = 9601 (0.335 sec)\n",
      "INFO:tensorflow:global_step/sec: 292.802\n",
      "INFO:tensorflow:loss = 113744340000.0, step = 9701 (0.342 sec)\n",
      "INFO:tensorflow:global_step/sec: 295.587\n",
      "INFO:tensorflow:loss = 103162690000.0, step = 9801 (0.338 sec)\n",
      "INFO:tensorflow:global_step/sec: 283.877\n",
      "INFO:tensorflow:loss = 42520580000.0, step = 9901 (0.355 sec)\n",
      "INFO:tensorflow:global_step/sec: 284.303\n",
      "INFO:tensorflow:loss = 110800550000.0, step = 10001 (0.349 sec)\n",
      "INFO:tensorflow:global_step/sec: 296.873\n",
      "INFO:tensorflow:loss = 45533385000.0, step = 10101 (0.337 sec)\n",
      "INFO:tensorflow:global_step/sec: 302.684\n",
      "INFO:tensorflow:loss = 27476267000.0, step = 10201 (0.331 sec)\n",
      "INFO:tensorflow:global_step/sec: 303.535\n",
      "INFO:tensorflow:loss = 59583140000.0, step = 10301 (0.329 sec)\n",
      "INFO:tensorflow:global_step/sec: 311.914\n",
      "INFO:tensorflow:loss = 135068590000.0, step = 10401 (0.321 sec)\n",
      "INFO:tensorflow:global_step/sec: 316.393\n",
      "INFO:tensorflow:loss = 175402070000.0, step = 10501 (0.316 sec)\n",
      "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 10550 vs previous value: 10550. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
      "INFO:tensorflow:global_step/sec: 339.293\n",
      "INFO:tensorflow:loss = 165070470000.0, step = 10601 (0.295 sec)\n",
      "INFO:tensorflow:global_step/sec: 311.211\n",
      "INFO:tensorflow:loss = 74715005000.0, step = 10701 (0.321 sec)\n",
      "INFO:tensorflow:global_step/sec: 310.895\n",
      "INFO:tensorflow:loss = 39189807000.0, step = 10801 (0.321 sec)\n",
      "INFO:tensorflow:global_step/sec: 276.089\n",
      "INFO:tensorflow:loss = 63258673000.0, step = 10901 (0.362 sec)\n",
      "INFO:tensorflow:global_step/sec: 329.817\n",
      "INFO:tensorflow:loss = 20767300000.0, step = 11001 (0.303 sec)\n",
      "INFO:tensorflow:global_step/sec: 297.177\n",
      "INFO:tensorflow:loss = 100069520000.0, step = 11101 (0.336 sec)\n",
      "INFO:tensorflow:global_step/sec: 279.104\n",
      "INFO:tensorflow:loss = 112801690000.0, step = 11201 (0.359 sec)\n",
      "INFO:tensorflow:global_step/sec: 295.224\n",
      "INFO:tensorflow:loss = 135262570000.0, step = 11301 (0.338 sec)\n",
      "INFO:tensorflow:global_step/sec: 301.888\n",
      "INFO:tensorflow:loss = 151432630000.0, step = 11401 (0.332 sec)\n",
      "INFO:tensorflow:global_step/sec: 290.611\n",
      "INFO:tensorflow:loss = 126518620000.0, step = 11501 (0.344 sec)\n",
      "INFO:tensorflow:global_step/sec: 284.886\n",
      "INFO:tensorflow:loss = 71957030000.0, step = 11601 (0.351 sec)\n",
      "INFO:tensorflow:global_step/sec: 301.962\n",
      "INFO:tensorflow:loss = 100796735000.0, step = 11701 (0.332 sec)\n",
      "INFO:tensorflow:global_step/sec: 302.442\n",
      "INFO:tensorflow:loss = 132653240000.0, step = 11801 (0.330 sec)\n",
      "INFO:tensorflow:global_step/sec: 307.921\n",
      "INFO:tensorflow:loss = 83274030000.0, step = 11901 (0.325 sec)\n",
      "INFO:tensorflow:global_step/sec: 234.681\n",
      "INFO:tensorflow:loss = 84867850000.0, step = 12001 (0.428 sec)\n",
      "INFO:tensorflow:global_step/sec: 258.532\n",
      "INFO:tensorflow:loss = 129374710000.0, step = 12101 (0.386 sec)\n",
      "INFO:tensorflow:global_step/sec: 242.34\n",
      "INFO:tensorflow:loss = 119276960000.0, step = 12201 (0.415 sec)\n",
      "INFO:tensorflow:global_step/sec: 278.391\n",
      "INFO:tensorflow:loss = 69730370000.0, step = 12301 (0.356 sec)\n",
      "INFO:tensorflow:global_step/sec: 274.556\n",
      "INFO:tensorflow:loss = 190003250000.0, step = 12401 (0.364 sec)\n",
      "INFO:tensorflow:global_step/sec: 306.807\n",
      "INFO:tensorflow:loss = 91762300000.0, step = 12501 (0.326 sec)\n",
      "INFO:tensorflow:global_step/sec: 293.197\n",
      "INFO:tensorflow:loss = 51234087000.0, step = 12601 (0.341 sec)\n",
      "INFO:tensorflow:global_step/sec: 272.217\n",
      "INFO:tensorflow:loss = 229895750000.0, step = 12701 (0.367 sec)\n",
      "INFO:tensorflow:global_step/sec: 271.471\n",
      "INFO:tensorflow:loss = 122462080000.0, step = 12801 (0.369 sec)\n",
      "INFO:tensorflow:global_step/sec: 277.569\n",
      "INFO:tensorflow:loss = 145970790000.0, step = 12901 (0.360 sec)\n",
      "INFO:tensorflow:global_step/sec: 258.996\n",
      "INFO:tensorflow:loss = 54325387000.0, step = 13001 (0.386 sec)\n",
      "INFO:tensorflow:global_step/sec: 286.703\n",
      "INFO:tensorflow:loss = 72821850000.0, step = 13101 (0.349 sec)\n",
      "INFO:tensorflow:global_step/sec: 295.768\n",
      "INFO:tensorflow:loss = 225535130000.0, step = 13201 (0.340 sec)\n",
      "INFO:tensorflow:global_step/sec: 296.281\n",
      "INFO:tensorflow:loss = 77723950000.0, step = 13301 (0.336 sec)\n",
      "INFO:tensorflow:global_step/sec: 318.432\n",
      "INFO:tensorflow:loss = 58822860000.0, step = 13401 (0.315 sec)\n",
      "INFO:tensorflow:global_step/sec: 306.856\n",
      "INFO:tensorflow:loss = 115539540000.0, step = 13501 (0.325 sec)\n",
      "INFO:tensorflow:global_step/sec: 308.625\n",
      "INFO:tensorflow:loss = 34038063000.0, step = 13601 (0.325 sec)\n",
      "INFO:tensorflow:global_step/sec: 282.768\n",
      "INFO:tensorflow:loss = 89884200000.0, step = 13701 (0.353 sec)\n",
      "INFO:tensorflow:global_step/sec: 296.826\n",
      "INFO:tensorflow:loss = 222950260000.0, step = 13801 (0.337 sec)\n",
      "INFO:tensorflow:global_step/sec: 297.598\n",
      "INFO:tensorflow:loss = 58288760000.0, step = 13901 (0.336 sec)\n",
      "INFO:tensorflow:global_step/sec: 317.98\n",
      "INFO:tensorflow:loss = 126928904000.0, step = 14001 (0.315 sec)\n",
      "INFO:tensorflow:global_step/sec: 295.846\n",
      "INFO:tensorflow:loss = 225631880000.0, step = 14101 (0.339 sec)\n",
      "INFO:tensorflow:global_step/sec: 309.007\n",
      "INFO:tensorflow:loss = 56376173000.0, step = 14201 (0.323 sec)\n",
      "INFO:tensorflow:global_step/sec: 324.933\n",
      "INFO:tensorflow:loss = 119436570000.0, step = 14301 (0.308 sec)\n",
      "INFO:tensorflow:global_step/sec: 190.26\n",
      "INFO:tensorflow:loss = 177189370000.0, step = 14401 (0.528 sec)\n",
      "INFO:tensorflow:global_step/sec: 227.629\n",
      "INFO:tensorflow:loss = 53248270000.0, step = 14501 (0.437 sec)\n",
      "INFO:tensorflow:global_step/sec: 185.804\n",
      "INFO:tensorflow:loss = 150191460000.0, step = 14601 (0.540 sec)\n",
      "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 14641 vs previous value: 14641. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
      "INFO:tensorflow:global_step/sec: 192.97\n",
      "INFO:tensorflow:loss = 108043450000.0, step = 14701 (0.517 sec)\n",
      "INFO:tensorflow:global_step/sec: 312.98\n",
      "INFO:tensorflow:loss = 63528976000.0, step = 14801 (0.320 sec)\n",
      "INFO:tensorflow:global_step/sec: 329.364\n",
      "INFO:tensorflow:loss = 81691870000.0, step = 14901 (0.304 sec)\n",
      "INFO:tensorflow:global_step/sec: 302.898\n",
      "INFO:tensorflow:loss = 210462670000.0, step = 15001 (0.330 sec)\n",
      "INFO:tensorflow:global_step/sec: 306.169\n",
      "INFO:tensorflow:loss = 83143200000.0, step = 15101 (0.326 sec)\n",
      "INFO:tensorflow:global_step/sec: 315.165\n",
      "INFO:tensorflow:loss = 57776038000.0, step = 15201 (0.317 sec)\n",
      "INFO:tensorflow:global_step/sec: 325.666\n",
      "INFO:tensorflow:loss = 112328065000.0, step = 15301 (0.307 sec)\n",
      "INFO:tensorflow:global_step/sec: 282.705\n",
      "INFO:tensorflow:loss = 134435650000.0, step = 15401 (0.353 sec)\n",
      "INFO:tensorflow:global_step/sec: 307.223\n",
      "INFO:tensorflow:loss = 112961840000.0, step = 15501 (0.326 sec)\n",
      "INFO:tensorflow:global_step/sec: 308.845\n",
      "INFO:tensorflow:loss = 56221753000.0, step = 15601 (0.324 sec)\n",
      "INFO:tensorflow:global_step/sec: 264.905\n",
      "INFO:tensorflow:loss = 105715100000.0, step = 15701 (0.384 sec)\n",
      "INFO:tensorflow:global_step/sec: 177.813\n",
      "INFO:tensorflow:loss = 80947910000.0, step = 15801 (0.557 sec)\n",
      "INFO:tensorflow:global_step/sec: 238.156\n",
      "INFO:tensorflow:loss = 48950410000.0, step = 15901 (0.426 sec)\n",
      "INFO:tensorflow:global_step/sec: 235.781\n",
      "INFO:tensorflow:loss = 52327230000.0, step = 16001 (0.417 sec)\n",
      "INFO:tensorflow:global_step/sec: 323.213\n",
      "INFO:tensorflow:loss = 88721230000.0, step = 16101 (0.309 sec)\n",
      "INFO:tensorflow:global_step/sec: 343.68\n",
      "INFO:tensorflow:loss = 48831670000.0, step = 16201 (0.291 sec)\n",
      "INFO:tensorflow:global_step/sec: 302.224\n",
      "INFO:tensorflow:loss = 94887980000.0, step = 16301 (0.331 sec)\n",
      "INFO:tensorflow:global_step/sec: 301.257\n",
      "INFO:tensorflow:loss = 118895790000.0, step = 16401 (0.332 sec)\n",
      "INFO:tensorflow:global_step/sec: 295.068\n",
      "INFO:tensorflow:loss = 55749630000.0, step = 16501 (0.339 sec)\n",
      "INFO:tensorflow:global_step/sec: 296.956\n",
      "INFO:tensorflow:loss = 53817164000.0, step = 16601 (0.337 sec)\n",
      "INFO:tensorflow:global_step/sec: 299.245\n",
      "INFO:tensorflow:loss = 78270880000.0, step = 16701 (0.335 sec)\n",
      "INFO:tensorflow:global_step/sec: 299.488\n",
      "INFO:tensorflow:loss = 68560257000.0, step = 16801 (0.334 sec)\n",
      "INFO:tensorflow:global_step/sec: 306.188\n",
      "INFO:tensorflow:loss = 137530590000.0, step = 16901 (0.327 sec)\n",
      "INFO:tensorflow:global_step/sec: 325.72\n",
      "INFO:tensorflow:loss = 62534836000.0, step = 17001 (0.308 sec)\n",
      "INFO:tensorflow:global_step/sec: 354.101\n",
      "INFO:tensorflow:loss = 79676965000.0, step = 17101 (0.280 sec)\n",
      "INFO:tensorflow:global_step/sec: 312.71\n",
      "INFO:tensorflow:loss = 67344556000.0, step = 17201 (0.320 sec)\n",
      "INFO:tensorflow:global_step/sec: 329.062\n",
      "INFO:tensorflow:loss = 34401260000.0, step = 17301 (0.304 sec)\n",
      "INFO:tensorflow:global_step/sec: 326.976\n",
      "INFO:tensorflow:loss = 173993410000.0, step = 17401 (0.305 sec)\n",
      "INFO:tensorflow:global_step/sec: 224.652\n",
      "INFO:tensorflow:loss = 132077810000.0, step = 17501 (0.449 sec)\n",
      "INFO:tensorflow:global_step/sec: 278.61\n",
      "INFO:tensorflow:loss = 73928016000.0, step = 17601 (0.356 sec)\n",
      "INFO:tensorflow:global_step/sec: 280.896\n",
      "INFO:tensorflow:loss = 30546610000.0, step = 17701 (0.357 sec)\n",
      "INFO:tensorflow:global_step/sec: 319.21\n",
      "INFO:tensorflow:loss = 20940591000.0, step = 17801 (0.311 sec)\n",
      "INFO:tensorflow:global_step/sec: 258.661\n",
      "INFO:tensorflow:loss = 78333670000.0, step = 17901 (0.388 sec)\n",
      "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 17911 vs previous value: 17911. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
      "INFO:tensorflow:global_step/sec: 326.977\n",
      "INFO:tensorflow:loss = 91022080000.0, step = 18001 (0.304 sec)\n",
      "INFO:tensorflow:global_step/sec: 273.114\n",
      "INFO:tensorflow:loss = 170888230000.0, step = 18101 (0.366 sec)\n",
      "INFO:tensorflow:global_step/sec: 312.427\n",
      "INFO:tensorflow:loss = 82951160000.0, step = 18201 (0.320 sec)\n",
      "INFO:tensorflow:global_step/sec: 302.827\n",
      "INFO:tensorflow:loss = 113239850000.0, step = 18301 (0.334 sec)\n",
      "INFO:tensorflow:global_step/sec: 285.656\n",
      "INFO:tensorflow:loss = 196461360000.0, step = 18401 (0.346 sec)\n",
      "INFO:tensorflow:global_step/sec: 330.585\n",
      "INFO:tensorflow:loss = 58343630000.0, step = 18501 (0.305 sec)\n",
      "INFO:tensorflow:global_step/sec: 323.135\n",
      "INFO:tensorflow:loss = 178572500000.0, step = 18601 (0.307 sec)\n",
      "INFO:tensorflow:global_step/sec: 310.783\n",
      "INFO:tensorflow:loss = 50398806000.0, step = 18701 (0.322 sec)\n",
      "INFO:tensorflow:global_step/sec: 259.572\n",
      "INFO:tensorflow:loss = 38208147000.0, step = 18801 (0.386 sec)\n",
      "INFO:tensorflow:global_step/sec: 288.59\n",
      "INFO:tensorflow:loss = 79130750000.0, step = 18901 (0.346 sec)\n",
      "INFO:tensorflow:global_step/sec: 302.811\n",
      "INFO:tensorflow:loss = 216724110000.0, step = 19001 (0.330 sec)\n",
      "INFO:tensorflow:global_step/sec: 312.388\n",
      "INFO:tensorflow:loss = 185546930000.0, step = 19101 (0.321 sec)\n",
      "INFO:tensorflow:global_step/sec: 301.999\n",
      "INFO:tensorflow:loss = 97709990000.0, step = 19201 (0.331 sec)\n",
      "INFO:tensorflow:global_step/sec: 299.178\n",
      "INFO:tensorflow:loss = 137961230000.0, step = 19301 (0.334 sec)\n",
      "INFO:tensorflow:global_step/sec: 294.007\n",
      "INFO:tensorflow:loss = 74811090000.0, step = 19401 (0.340 sec)\n",
      "INFO:tensorflow:global_step/sec: 298.216\n",
      "INFO:tensorflow:loss = 60249200000.0, step = 19501 (0.335 sec)\n",
      "INFO:tensorflow:global_step/sec: 277.839\n",
      "INFO:tensorflow:loss = 72361880000.0, step = 19601 (0.360 sec)\n",
      "INFO:tensorflow:global_step/sec: 301.303\n",
      "INFO:tensorflow:loss = 51978904000.0, step = 19701 (0.332 sec)\n",
      "INFO:tensorflow:global_step/sec: 333.107\n",
      "INFO:tensorflow:loss = 113573230000.0, step = 19801 (0.301 sec)\n",
      "INFO:tensorflow:global_step/sec: 339.526\n",
      "INFO:tensorflow:loss = 112154160000.0, step = 19901 (0.295 sec)\n",
      "INFO:tensorflow:global_step/sec: 326.029\n",
      "INFO:tensorflow:loss = 67278100000.0, step = 20001 (0.306 sec)\n",
      "INFO:tensorflow:global_step/sec: 310.334\n",
      "INFO:tensorflow:loss = 160666290000.0, step = 20101 (0.322 sec)\n",
      "INFO:tensorflow:global_step/sec: 299.901\n",
      "INFO:tensorflow:loss = 97135130000.0, step = 20201 (0.334 sec)\n",
      "INFO:tensorflow:global_step/sec: 280.348\n",
      "INFO:tensorflow:loss = 62239343000.0, step = 20301 (0.357 sec)\n",
      "INFO:tensorflow:global_step/sec: 306.373\n",
      "INFO:tensorflow:loss = 89090000000.0, step = 20401 (0.326 sec)\n",
      "INFO:tensorflow:global_step/sec: 279.958\n",
      "INFO:tensorflow:loss = 85299590000.0, step = 20501 (0.359 sec)\n",
      "INFO:tensorflow:global_step/sec: 310.998\n",
      "INFO:tensorflow:loss = 78964376000.0, step = 20601 (0.320 sec)\n",
      "INFO:tensorflow:global_step/sec: 282.999\n",
      "INFO:tensorflow:loss = 59557966000.0, step = 20701 (0.356 sec)\n",
      "INFO:tensorflow:global_step/sec: 268.464\n",
      "INFO:tensorflow:loss = 86185460000.0, step = 20801 (0.377 sec)\n",
      "INFO:tensorflow:global_step/sec: 266.898\n",
      "INFO:tensorflow:loss = 88412720000.0, step = 20901 (0.376 sec)\n",
      "INFO:tensorflow:global_step/sec: 301.573\n",
      "INFO:tensorflow:loss = 142069990000.0, step = 21001 (0.327 sec)\n",
      "INFO:tensorflow:global_step/sec: 307.841\n",
      "INFO:tensorflow:loss = 78272040000.0, step = 21101 (0.326 sec)\n",
      "INFO:tensorflow:global_step/sec: 289.305\n",
      "INFO:tensorflow:loss = 179473120000.0, step = 21201 (0.340 sec)\n",
      "INFO:tensorflow:global_step/sec: 301.792\n",
      "INFO:tensorflow:loss = 125251084000.0, step = 21301 (0.332 sec)\n",
      "INFO:tensorflow:global_step/sec: 280.315\n",
      "INFO:tensorflow:loss = 52868858000.0, step = 21401 (0.356 sec)\n",
      "INFO:tensorflow:global_step/sec: 323.173\n",
      "INFO:tensorflow:loss = 138426480000.0, step = 21501 (0.310 sec)\n",
      "INFO:tensorflow:global_step/sec: 248.189\n",
      "INFO:tensorflow:loss = 96468160000.0, step = 21601 (0.404 sec)\n",
      "INFO:tensorflow:global_step/sec: 307.435\n",
      "INFO:tensorflow:loss = 47951160000.0, step = 21701 (0.324 sec)\n",
      "INFO:tensorflow:global_step/sec: 327.348\n",
      "INFO:tensorflow:loss = 62410510000.0, step = 21801 (0.306 sec)\n",
      "INFO:tensorflow:global_step/sec: 314.702\n",
      "INFO:tensorflow:loss = 76416295000.0, step = 21901 (0.317 sec)\n",
      "INFO:tensorflow:global_step/sec: 307.917\n",
      "INFO:tensorflow:loss = 101614000000.0, step = 22001 (0.325 sec)\n",
      "INFO:tensorflow:global_step/sec: 294.975\n",
      "INFO:tensorflow:loss = 67443850000.0, step = 22101 (0.340 sec)\n",
      "INFO:tensorflow:global_step/sec: 316.034\n",
      "INFO:tensorflow:loss = 52110830000.0, step = 22201 (0.315 sec)\n",
      "INFO:tensorflow:global_step/sec: 318.584\n",
      "INFO:tensorflow:loss = 172702840000.0, step = 22301 (0.315 sec)\n",
      "INFO:tensorflow:global_step/sec: 318.04\n",
      "INFO:tensorflow:loss = 70696180000.0, step = 22401 (0.314 sec)\n",
      "INFO:tensorflow:global_step/sec: 324.061\n",
      "INFO:tensorflow:loss = 87655930000.0, step = 22501 (0.309 sec)\n",
      "INFO:tensorflow:global_step/sec: 301.223\n",
      "INFO:tensorflow:loss = 82780160000.0, step = 22601 (0.332 sec)\n",
      "INFO:tensorflow:global_step/sec: 277.985\n",
      "INFO:tensorflow:loss = 59992140000.0, step = 22701 (0.361 sec)\n",
      "INFO:tensorflow:global_step/sec: 274.672\n",
      "INFO:tensorflow:loss = 74215740000.0, step = 22801 (0.363 sec)\n",
      "INFO:tensorflow:global_step/sec: 301.818\n",
      "INFO:tensorflow:loss = 143532930000.0, step = 22901 (0.332 sec)\n",
      "INFO:tensorflow:global_step/sec: 281.843\n",
      "INFO:tensorflow:loss = 66619875000.0, step = 23001 (0.355 sec)\n",
      "INFO:tensorflow:global_step/sec: 302.12\n",
      "INFO:tensorflow:loss = 71483600000.0, step = 23101 (0.331 sec)\n",
      "INFO:tensorflow:global_step/sec: 313.772\n",
      "INFO:tensorflow:loss = 46738625000.0, step = 23201 (0.318 sec)\n",
      "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 23205 vs previous value: 23205. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
      "INFO:tensorflow:global_step/sec: 305.191\n",
      "INFO:tensorflow:loss = 79899210000.0, step = 23301 (0.328 sec)\n",
      "INFO:tensorflow:global_step/sec: 291.66\n",
      "INFO:tensorflow:loss = 76555485000.0, step = 23401 (0.343 sec)\n",
      "INFO:tensorflow:global_step/sec: 317.454\n",
      "INFO:tensorflow:loss = 60093694000.0, step = 23501 (0.315 sec)\n",
      "INFO:tensorflow:global_step/sec: 287.576\n",
      "INFO:tensorflow:loss = 102563940000.0, step = 23601 (0.348 sec)\n",
      "INFO:tensorflow:global_step/sec: 322.262\n",
      "INFO:tensorflow:loss = 76513714000.0, step = 23701 (0.311 sec)\n",
      "INFO:tensorflow:global_step/sec: 305.02\n",
      "INFO:tensorflow:loss = 44910174000.0, step = 23801 (0.327 sec)\n",
      "INFO:tensorflow:global_step/sec: 316.761\n",
      "INFO:tensorflow:loss = 105684976000.0, step = 23901 (0.316 sec)\n",
      "INFO:tensorflow:global_step/sec: 306.298\n",
      "INFO:tensorflow:loss = 86528020000.0, step = 24001 (0.326 sec)\n",
      "INFO:tensorflow:global_step/sec: 299.318\n",
      "INFO:tensorflow:loss = 95056530000.0, step = 24101 (0.334 sec)\n",
      "INFO:tensorflow:global_step/sec: 313.846\n",
      "INFO:tensorflow:loss = 130860980000.0, step = 24201 (0.319 sec)\n",
      "INFO:tensorflow:global_step/sec: 272.605\n",
      "INFO:tensorflow:loss = 115475430000.0, step = 24301 (0.367 sec)\n",
      "INFO:tensorflow:global_step/sec: 304.749\n",
      "INFO:tensorflow:loss = 68056003000.0, step = 24401 (0.328 sec)\n",
      "INFO:tensorflow:global_step/sec: 305.919\n",
      "INFO:tensorflow:loss = 204314720000.0, step = 24501 (0.327 sec)\n",
      "INFO:tensorflow:global_step/sec: 303.031\n",
      "INFO:tensorflow:loss = 154236220000.0, step = 24601 (0.330 sec)\n",
      "INFO:tensorflow:global_step/sec: 312.409\n",
      "INFO:tensorflow:loss = 35894346000.0, step = 24701 (0.320 sec)\n",
      "INFO:tensorflow:global_step/sec: 316.235\n",
      "INFO:tensorflow:loss = 86013950000.0, step = 24801 (0.316 sec)\n",
      "INFO:tensorflow:global_step/sec: 300.609\n",
      "INFO:tensorflow:loss = 112164720000.0, step = 24901 (0.333 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 25000 into /var/folders/0y/41vh8h4d1wv2yccr48slhmgc0000gn/T/tmpzyv8rm11/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 51291177000.0.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow_estimator.python.estimator.canned.dnn.DNNRegressor at 0x1a415ad9e8>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train(input_fn=input_func,steps=25000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Create a prediction input function and then use the .predict method off your estimator model to create a list or predictions on your test data. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_input_func = tf.estimator.inputs.pandas_input_fn(\n",
    "      x=X_test,\n",
    "      batch_size=10,\n",
    "      num_epochs=1,\n",
    "      shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_gen = model.predict(predict_input_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/0y/41vh8h4d1wv2yccr48slhmgc0000gn/T/tmpzyv8rm11/model.ckpt-25000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    }
   ],
   "source": [
    "predictions = list(pred_gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Calculate the RMSE. Do this manually or use [sklearn.metrics](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_squared_error.html) **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_preds = []\n",
    "for pred in predictions:\n",
    "    final_preds.append(pred['predictions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98365.30777898831"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test,final_preds)**0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Great Job!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
